{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "textgenie-examples.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4b69iyum-FxW",
        "outputId": "8fb63125-6ac3-4fc8-c4c1-20fcfea72e31"
      },
      "source": [
        "!pip install --upgrade textgenie"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/hetpandya/textgenie.git\n",
            "  Cloning https://github.com/hetpandya/textgenie.git to /tmp/pip-req-build-42y38bmw\n",
            "  Running command git clone -q https://github.com/hetpandya/textgenie.git /tmp/pip-req-build-42y38bmw\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from textgenie==0.1.2) (1.9.0+cu102)\n",
            "Requirement already satisfied, skipping upgrade: transformers in /usr/local/lib/python3.7/dist-packages (from textgenie==0.1.2) (4.7.0)\n",
            "Requirement already satisfied, skipping upgrade: sentencepiece in /usr/local/lib/python3.7/dist-packages (from textgenie==0.1.2) (0.1.96)\n",
            "Requirement already satisfied, skipping upgrade: spacy in /usr/local/lib/python3.7/dist-packages (from textgenie==0.1.2) (2.2.4)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from textgenie==0.1.2) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: pattern in /usr/local/lib/python3.7/dist-packages (from textgenie==0.1.2) (3.6)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.5.0->textgenie==0.1.2) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->textgenie==0.1.2) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from transformers->textgenie==0.1.2) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers->textgenie==0.1.2) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers->textgenie==0.1.2) (4.5.0)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->textgenie==0.1.2) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers->textgenie==0.1.2) (0.0.8)\n",
            "Requirement already satisfied, skipping upgrade: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers->textgenie==0.1.2) (0.10.3)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers->textgenie==0.1.2) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from transformers->textgenie==0.1.2) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers->textgenie==0.1.2) (0.0.45)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy->textgenie==0.1.2) (1.1.3)\n",
            "Requirement already satisfied, skipping upgrade: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->textgenie==0.1.2) (7.4.0)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->textgenie==0.1.2) (2.0.5)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->textgenie==0.1.2) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy->textgenie==0.1.2) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->textgenie==0.1.2) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy->textgenie==0.1.2) (57.0.0)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy->textgenie==0.1.2) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->textgenie==0.1.2) (0.8.2)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->textgenie==0.1.2) (3.0.5)\n",
            "Requirement already satisfied, skipping upgrade: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from pattern->textgenie==0.1.2) (4.6.3)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.7/dist-packages (from pattern->textgenie==0.1.2) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: feedparser in /usr/local/lib/python3.7/dist-packages (from pattern->textgenie==0.1.2) (6.0.7)\n",
            "Requirement already satisfied, skipping upgrade: lxml in /usr/local/lib/python3.7/dist-packages (from pattern->textgenie==0.1.2) (4.2.6)\n",
            "Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.7/dist-packages (from pattern->textgenie==0.1.2) (3.2.5)\n",
            "Requirement already satisfied, skipping upgrade: cherrypy in /usr/local/lib/python3.7/dist-packages (from pattern->textgenie==0.1.2) (18.6.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from pattern->textgenie==0.1.2) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: pdfminer.six in /usr/local/lib/python3.7/dist-packages (from pattern->textgenie==0.1.2) (20201018)\n",
            "Requirement already satisfied, skipping upgrade: python-docx in /usr/local/lib/python3.7/dist-packages (from pattern->textgenie==0.1.2) (0.8.11)\n",
            "Requirement already satisfied, skipping upgrade: backports.csv in /usr/local/lib/python3.7/dist-packages (from pattern->textgenie==0.1.2) (1.0.7)\n",
            "Requirement already satisfied, skipping upgrade: mysqlclient in /usr/local/lib/python3.7/dist-packages (from pattern->textgenie==0.1.2) (2.0.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->textgenie==0.1.2) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->textgenie==0.1.2) (2021.5.30)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->textgenie==0.1.2) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers->textgenie==0.1.2) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers->textgenie==0.1.2) (3.4.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers->textgenie==0.1.2) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->textgenie==0.1.2) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->textgenie==0.1.2) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->textgenie==0.1.2) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: sgmllib3k in /usr/local/lib/python3.7/dist-packages (from feedparser->pattern->textgenie==0.1.2) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: cheroot>=8.2.1 in /usr/local/lib/python3.7/dist-packages (from cherrypy->pattern->textgenie==0.1.2) (8.5.2)\n",
            "Requirement already satisfied, skipping upgrade: zc.lockfile in /usr/local/lib/python3.7/dist-packages (from cherrypy->pattern->textgenie==0.1.2) (2.0)\n",
            "Requirement already satisfied, skipping upgrade: jaraco.collections in /usr/local/lib/python3.7/dist-packages (from cherrypy->pattern->textgenie==0.1.2) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: more-itertools in /usr/local/lib/python3.7/dist-packages (from cherrypy->pattern->textgenie==0.1.2) (8.8.0)\n",
            "Requirement already satisfied, skipping upgrade: portend>=2.1.1 in /usr/local/lib/python3.7/dist-packages (from cherrypy->pattern->textgenie==0.1.2) (2.7.1)\n",
            "Requirement already satisfied, skipping upgrade: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from pdfminer.six->pattern->textgenie==0.1.2) (2.4.0)\n",
            "Requirement already satisfied, skipping upgrade: cryptography in /usr/local/lib/python3.7/dist-packages (from pdfminer.six->pattern->textgenie==0.1.2) (3.4.7)\n",
            "Requirement already satisfied, skipping upgrade: jaraco.functools in /usr/local/lib/python3.7/dist-packages (from cheroot>=8.2.1->cherrypy->pattern->textgenie==0.1.2) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: jaraco.classes in /usr/local/lib/python3.7/dist-packages (from jaraco.collections->cherrypy->pattern->textgenie==0.1.2) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: jaraco.text in /usr/local/lib/python3.7/dist-packages (from jaraco.collections->cherrypy->pattern->textgenie==0.1.2) (3.5.0)\n",
            "Requirement already satisfied, skipping upgrade: tempora>=1.8 in /usr/local/lib/python3.7/dist-packages (from portend>=2.1.1->cherrypy->pattern->textgenie==0.1.2) (4.1.1)\n",
            "Requirement already satisfied, skipping upgrade: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography->pdfminer.six->pattern->textgenie==0.1.2) (1.14.5)\n",
            "Requirement already satisfied, skipping upgrade: pytz in /usr/local/lib/python3.7/dist-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern->textgenie==0.1.2) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography->pdfminer.six->pattern->textgenie==0.1.2) (2.20)\n",
            "Building wheels for collected packages: textgenie\n",
            "  Building wheel for textgenie (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for textgenie: filename=textgenie-0.1.2-cp37-none-any.whl size=8705 sha256=f8cb665c1c8c93f7792b85d66124020d326625f21d43873fb6d0db71f67437af\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8giac7ls/wheels/35/24/87/4f20f5d3fa823cf98bf2d27bb95281c19c3436f82888aa6adc\n",
            "Successfully built textgenie\n",
            "Installing collected packages: textgenie\n",
            "  Found existing installation: textgenie 0.1.1\n",
            "    Uninstalling textgenie-0.1.1:\n",
            "      Successfully uninstalled textgenie-0.1.1\n",
            "Successfully installed textgenie-0.1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "textgenie"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_h3lGuIV-KKI"
      },
      "source": [
        "from textgenie import TextGenie"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tg2igVb6-UxL",
        "outputId": "790b4af8-9eb8-42ed-cf01-cb9cb5555e72"
      },
      "source": [
        "textgenie = TextGenie(\"ramsrigouthamg/t5_paraphraser\",'bert-base-uncased')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Paraphrase Model..\n",
            "Loading Mask Fill Model..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P06v8CkK-vHu",
        "outputId": "bec9a13a-58cd-4f91-bf1c-f2f652fff9e5"
      },
      "source": [
        "# Augment a list of sentences\n",
        "sentences = [\"The video was posted on Facebook by Alex.\",\"I plan to run it again this time\"]\n",
        "textgenie.magic_lamp(sentences,\"paraphrase: \",n_paraphrase_predictions=15,n_mask_predictions=15,convert_to_active=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/2 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2111: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/t5/tokenization_t5.py:191: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  f\"This sequence already has {self.eos_token}. In future versions this behavior may lead to duplicated eos tokens being added.\"\n",
            "100%|██████████| 2/2 [00:18<00:00,  9.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Completed writing output to /content/sentences_aug.txt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the clip was posted on facebook by alex.',\n",
              " 'the video was posted on facebook by youtube.',\n",
              " 'the event was posted on facebook by alex.',\n",
              " 'the text was posted on facebook by alex.',\n",
              " 'the cover was posted on facebook by alex.',\n",
              " 'the story was posted on facebook by alex.',\n",
              " 'the article was posted on facebook by alex.',\n",
              " 'the film was posted on facebook by alex.',\n",
              " 'the video was posted on facebook by twitter.',\n",
              " 'Is it true that the video, posted in Facebook, was created by Alex?',\n",
              " 'the photo was posted on facebook by alex.',\n",
              " 'What videos have you seen on FaceBook (Alex)?',\n",
              " 'If I could capture this on Facebook, what would be the point of posting an Instagram video?',\n",
              " 'I just saw the video posted on Facebook by Alex Wenzel. This will impact to tell you more than we realise.',\n",
              " 'the video was posted on blogs by alex.',\n",
              " 'the video was posted on facebook by mtv.',\n",
              " 'the video was posted on youtube by alex.',\n",
              " 'the video was posted on tv by alex.',\n",
              " 'the video was posted on facebook by anonymous.',\n",
              " 'the single was posted on facebook by alex.',\n",
              " 'the video was posted on vine by alex.',\n",
              " 'the video was posted on facebook by rihanna.',\n",
              " 'the video was posted on facebook by members.',\n",
              " 'the video was posted on twitch by alex.',\n",
              " 'the video was posted on facebook by others.',\n",
              " 'the video was posted on amazon by alex.',\n",
              " 'the video was posted on facebook by fans.',\n",
              " 'Alex posted the video on Facebook. ',\n",
              " 'The video was posted on Facebook by Alex Pease.',\n",
              " 'the video was posted on facebook by fox.',\n",
              " 'the video was posted on facebook by her.',\n",
              " 'the video was posted on google by alex.',\n",
              " 'the video was posted on facebook by himself.',\n",
              " 'the song was posted on facebook by alex.',\n",
              " 'the video was posted on itunes by alex.',\n",
              " 'the video was posted on video by alex.',\n",
              " 'the video was posted on twitter by alex.',\n",
              " 'the video was posted on facebook by rt.',\n",
              " 'the video was posted on myspace by alex.',\n",
              " 'the video was posted on site by alex.',\n",
              " 'the trailer was posted on facebook by alex.',\n",
              " \"Watch Alex Rodriguez' Facebook video here.\",\n",
              " 'the video was posted on facebook by friends.',\n",
              " \"This video was posted on Facebook by Alex. I've been using a mobile app for the past few days but just cant seem to find the time to download it.\",\n",
              " 'the track was posted on facebook by alex.',\n",
              " 'the video was posted on mtv by alex.',\n",
              " 'the album was posted on facebook by alex.',\n",
              " 'This is a viral video I uploaded to Facebook and showed on my Facebook profile.',\n",
              " 'The video was posted on Facebook by Alex.',\n",
              " 'the announcement was posted on facebook by alex.',\n",
              " 'the video was posted on facebook by them.',\n",
              " 'the video was posted on internet by alex.',\n",
              " 'the video was posted on facebook by him.',\n",
              " 'i plan to run it again this month',\n",
              " 'i plan to run it again this.',\n",
              " 'i plan to run it again this week',\n",
              " 'I plan to run it again this time this time.',\n",
              " 'Is it possible to run it again after it starts if you want it again?',\n",
              " 'I plan to run it again this time this time this time I know the plot. I guess they will be able to continue to run it then.',\n",
              " 'i plan to run it again this ;',\n",
              " \"I plan to run this again this time this time around. I'll be writing more frequently than I have the time and the plan is much less complex.\",\n",
              " 'I plan to run it again this time this time this time.',\n",
              " \"I plan to run it again this time this time this time. I'm sure that I'll be able to find a runner again.\",\n",
              " 'I plan to run it again this time',\n",
              " \"I plan to run it again this time this time again this time I can't remember whether I really needed to keep it running but its good enough.\",\n",
              " 'I will run it again. I plan to run it again this time.',\n",
              " \"I'll run it now again but the second time I've completed.\",\n",
              " 'I plan to run it again this time this time. It actually helps me. So, I will run it again.',\n",
              " 'i plan to run it again this day',\n",
              " 'i plan to run it again this...',\n",
              " 'i plan to run it again this year',\n",
              " 'i plan to run it again this summer',\n",
              " 'What is the plan to run it again?',\n",
              " 'I plan to run It again this time now this time in Linux.',\n",
              " 'How is this book going to be run again?',\n",
              " 'i plan to run it again this season',\n",
              " \"I plan to run it again this time I'm not going to run it again this time. If I didn't run it, I don't expect to miss out on it.\",\n",
              " 'i plan to run it again this weekend',\n",
              " 'i plan to run it again this!',\n",
              " 'i plan to run it again this semester',\n",
              " 'i plan to run it again this?',\n",
              " 'i plan to run it again this morning',\n",
              " 'I can always run it again, I just want to try putting it back. This time a fortnight after.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fN8rA8bc-cF1",
        "outputId": "93d4aafb-5027-4c13-9f49-c7a54777cc7e"
      },
      "source": [
        "%%writefile sentences.txt\n",
        "At dinner, six shrimp were eaten by Harry.\n",
        "Beautiful giraffes roam the savannah."
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing sentences.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQLNyJyH-t_T",
        "outputId": "f3765c08-2fd7-4b3f-bc33-6413fe94e4c4"
      },
      "source": [
        "# Augment data in a txt file\n",
        "textgenie.magic_lamp(\"sentences.txt\",\"paraphrase: \",n_mask_predictions=5,convert_to_active=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/2 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2111: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/t5/tokenization_t5.py:191: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  f\"This sequence already has {self.eos_token}. In future versions this behavior may lead to duplicated eos tokens being added.\"\n",
            "100%|██████████| 2/2 [00:07<00:00,  3.70s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Completed writing output to /content/sentences_aug.txt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['at lunch, six shrimp were eaten by harry.',\n",
              " 'at dinner, six shrimp were eaten by hand.',\n",
              " 'at night, six shrimp were eaten by harry.',\n",
              " 'At dinner, Harry was having 6 shrimps.',\n",
              " 'At dinner, Harry ate six shrimp.',\n",
              " 'at least, six shrimp were eaten by harry.',\n",
              " 'at dinner, six shrimp were eaten by him.',\n",
              " 'at dinner, six shrimp were eaten by chicken.',\n",
              " 'at dinner, six pancakes were eaten by harry.',\n",
              " 'at dinner, six shrimp were eaten by everyone.',\n",
              " 'at dinner, his shrimp were eaten by harry.',\n",
              " \"During Harry's dinner, he ate eight shrimp.\",\n",
              " 'at dinner, her shrimp were eaten by harry.',\n",
              " 'at dinner, these shrimp were eaten by harry.',\n",
              " 'at dinner, six eggs were eaten by harry.',\n",
              " 'Harry ate six shrimp at dinner. ',\n",
              " 'Harry ate six shrimp.',\n",
              " 'at first, six shrimp were eaten by harry.',\n",
              " 'at dinner, the shrimp were eaten by harry.',\n",
              " 'at dinner, some shrimp were eaten by harry.',\n",
              " 'at dinner, six sandwiches were eaten by harry.',\n",
              " \"During Harry's dinner, six shrimp were eaten by Harry.\",\n",
              " 'At dinner, six shrimp were eaten by Harry.',\n",
              " 'at dinner, six dishes were eaten by harry.',\n",
              " 'at dinner, six meals were eaten by harry.',\n",
              " 'at dinner, six shrimp were eaten by themselves.',\n",
              " 'How many beautiful giraffes do you see in the savannah?',\n",
              " 'black giraffes roam the savannah.',\n",
              " 'little giraffes roam the savannah.',\n",
              " 'the giraffes roam the savannah.',\n",
              " 'beautiful giraffes roam the park.',\n",
              " 'beautiful butterflies roam the savannah.',\n",
              " 'beautiful giraffes roam the land.',\n",
              " 'Beautiful giraffes roam the savannah.',\n",
              " 'large giraffes roam the savannah.',\n",
              " 'What are some impressive giraffes that roam the Savannah?',\n",
              " 'beautiful birds roam the savannah.',\n",
              " 'beautiful giraffes roam the streets.',\n",
              " 'beautiful giraffes roam the grounds.',\n",
              " 'beautiful animals roam the savannah.',\n",
              " 'In winter, in the middle of nowhere, a giraffe roams the Sabana Desert. What do they do?',\n",
              " 'beautiful creatures roam the savannah.',\n",
              " 'Beautiful giraffes roam the Savanna.',\n",
              " 'wild giraffes roam the savannah.',\n",
              " 'beautiful women roam the savannah.',\n",
              " 'beautiful giraffes roam the beach.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzoLK-mq_H3e",
        "outputId": "eea8ad04-5cad-4094-b9d7-0dd601cec684"
      },
      "source": [
        "%%writefile dataset.csv\n",
        "Sue changed the flat tire., Label1\n",
        "The crew paved the entire stretch of highway., Label2\n",
        "The critic wrote a scathing review., Label1\n",
        "I will clean the house every Saturday., Label2 "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing dataset.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzW11dvT_eNw",
        "outputId": "cf322632-0ef5-46df-a672-9d955dcc1e20"
      },
      "source": [
        "# Augment data in a csv file with labels\n",
        "augmented_dataset = textgenie.magic_lamp(\"dataset.csv\",\"paraphrase: \",n_paraphrase_predictions=15,n_mask_predictions=15,convert_to_active=True,label_column=\"Label\",column_names=[\"Text\",\"Label\"])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/4 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2111: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/t5/tokenization_t5.py:191: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  f\"This sequence already has {self.eos_token}. In future versions this behavior may lead to duplicated eos tokens being added.\"\n",
            "100%|██████████| 4/4 [00:30<00:00,  7.73s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Completed writing output to /content/dataset_aug.csv.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "VdejwBeM_uWQ",
        "outputId": "23326c3a-a75d-4c9f-9d5d-09b58b37f252"
      },
      "source": [
        "augmented_dataset"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i changed the flat tire.</td>\n",
              "      <td>Label1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sue changed my flat tire.</td>\n",
              "      <td>Label1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In the end Sue changed the flat tire.</td>\n",
              "      <td>Label1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>She changed my tire to flat. How can she fix t...</td>\n",
              "      <td>Label1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>reacher changed the flat tire.</td>\n",
              "      <td>Label1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>i will clean the house every day.</td>\n",
              "      <td>Label2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>i will clean the house every evening.</td>\n",
              "      <td>Label2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226</th>\n",
              "      <td>I can clean the house every Saturday. I make a...</td>\n",
              "      <td>Label2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>I plan to clean the house every weekend. How d...</td>\n",
              "      <td>Label2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>I plan to clean our house every weekend. It's ...</td>\n",
              "      <td>Label2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>229 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Text   Label\n",
              "0                             i changed the flat tire.  Label1\n",
              "1                            Sue changed my flat tire.  Label1\n",
              "2                In the end Sue changed the flat tire.  Label1\n",
              "3    She changed my tire to flat. How can she fix t...  Label1\n",
              "4                       reacher changed the flat tire.  Label1\n",
              "..                                                 ...     ...\n",
              "224                  i will clean the house every day.  Label2\n",
              "225              i will clean the house every evening.  Label2\n",
              "226  I can clean the house every Saturday. I make a...  Label2\n",
              "227  I plan to clean the house every weekend. How d...  Label2\n",
              "228  I plan to clean our house every weekend. It's ...  Label2\n",
              "\n",
              "[229 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    }
  ]
}